{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe405aa0-a9ee-4fd2-9184-4d6836a8fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mean\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import regex as re\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328de8a-3afa-4813-8241-5e69e8231c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    xls = pd.ExcelFile('C:/Users/marke/DSCP/compost_data/MacPherson Feeding Logs.xlsx')\n",
    "    carbon_index = pd.read_excel(xls, 'Emission Carbon Index')\n",
    "    df2 = pd.read_excel(xls, 'Sep to Dec 2023')\n",
    "    df3 = pd.read_excel(xls, 'Jan to Jun 2024')\n",
    "\n",
    "    new_header = carbon_index.iloc[0] #grab the first row for the header\n",
    "    carbon_index = carbon_index[1:] #take the data less the header row\n",
    "    carbon_index.columns = new_header\n",
    "\n",
    "    carbon_index.drop('S/N', axis=1, inplace=True)\n",
    "\n",
    "    tank1 = df2['Tank 1']\n",
    "\n",
    "    return carbon_index, df2, df3, tank1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e202b1-1cd6-4483-886d-d6fd507c3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove 'distilled water' segment\n",
    "def remove_distilled_water(text):\n",
    "    # Regex to find 'xg of distilled water'\n",
    "    return re.sub(r'\\d+g of distilled water,?\\s*', '', text) # we remove distilled water as it is not able to give us a carbon value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034b6dc-c604-4aa2-888c-af2960631a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_dictionary(row): # we want to save the quantity of each food item first before removing it\n",
    "    if pd.notna(row):  # Check if the row is not NaN\n",
    "        # Find all numerical values in the row\n",
    "        numerical_values = re.findall(r'\\d+', row)\n",
    "        \n",
    "        # Store the numerical values in the dictionary\n",
    "        quantity_dict = numerical_values\n",
    "        \n",
    "        return numerical_values\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7197c1-2c82-4b9a-b8d8-e6a49198ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(row):\n",
    "    unwanted_words = {'of', 'dry', 'dried', 'wet', 'crushed', 'tops', 'tops,', 'skins', 'skins,', 'coffee'} \n",
    "    \n",
    "    if pd.notna(row):  # Check if the row is not NaN\n",
    "        # Flatten any nested lists\n",
    "        if isinstance(row, list):\n",
    "            row = ' '.join(row)\n",
    "        \n",
    "        # Split the text into words\n",
    "        words = row.split(\" \")\n",
    "        \n",
    "\n",
    "\n",
    "        # Filter out unwanted words and empty strings\n",
    "        filtered_words = [word for word in words if not any(char.isdigit() for char in word) and word.lower() not in unwanted_words]\n",
    "        cleaned_list = [item.strip(',') for item in filtered_words if item.strip(',')]\n",
    "        \n",
    "        return cleaned_list\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fddf89-b0c9-4fc3-a3b5-882ff0ac9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(tank1):\n",
    "    food_dict = carbon_index['Food Name'].to_dict()\n",
    "\n",
    "    food_info = carbon_index.set_index('Food Name').T.to_dict('list')\n",
    "\n",
    "    tank1 = tank1.str.replace('1 spoon', '15g')\n",
    "    tank1 = pd.DataFrame(tank1)\n",
    "\n",
    "    tank1['Tank 1'] = tank1['Tank 1'].str.replace('\\n', ', ').str.replace('(', ' ').str.replace(')', ' ')\n",
    "    tank1['Tank 1'] = tank1['Tank 1'].astype(str)\n",
    "    # Apply the function to the column\n",
    "    tank1['Tank 1'] = tank1['Tank 1'].apply(remove_distilled_water)\n",
    "\n",
    "\n",
    "\n",
    "    quantity_dict = {}\n",
    "    quantity_dict = tank1['Tank 1'].apply(quantity_dictionary)\n",
    "\n",
    "    df_split = tank1['Tank 1'].apply(split_text)\n",
    "\n",
    "    for i in range(len(df_split)):\n",
    "        for j in range(len(df_split[i])):\n",
    "            if df_split[i][j] == \"grinds\": \n",
    "                df_split[i][j] = \"Coffee Grounds\"\n",
    "            \n",
    "            if df_split[i][j] == \"grounds\":\n",
    "                df_split[i][j] = \"Grounded Coffee\"\n",
    "\n",
    "    processed_sentences = df_split.copy()\n",
    "\n",
    "    return food_dict, food_info, tank1, quantity_dict, processed_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18257983-9730-49ea-bb00-5d11cffd8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrase_vector(phrase, model):\n",
    "    words = phrase.lower().split()\n",
    "    vectors = [model[word] for word in words if word in model]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213c455-3812-4510-b6d0-5497763cd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model):\n",
    "    # Load the model\n",
    "    #model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# List of words to be processed\n",
    "    words_list = food_dict\n",
    "\n",
    "    word_list_vectors = {phrase: get_phrase_vector(phrase, model) for phrase in words_list.values()}\n",
    "\n",
    "    return word_list_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ef963-9be0-4f96-b682-877ac4fd8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_phrase(phrase):\n",
    "    phrase_vector = get_phrase_vector(phrase, model)\n",
    "    similarities = {key: cosine_similarity([phrase_vector], [vector])[0][0] for key, vector in word_list_vectors.items()}\n",
    "    # Ensure the phrase is not in the result if it's not a close match\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    most_similar_phrase = sorted_similarities[0][0] if sorted_similarities and sorted_similarities[0][1] > 0.5 else None\n",
    "    return most_similar_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beccc1a-8fa3-40bf-89c1-37d22110b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_phrase(phrase):\n",
    "    phrase_vector = get_phrase_vector(phrase, model)\n",
    "    similarities = {key: cosine_similarity([phrase_vector], [vector])[0][0] for key, vector in word_list_vectors.items()}\n",
    "    # Ensure the phrase is not in the result if it's not a close match\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    most_similar_phrase = sorted_similarities[0][0] if sorted_similarities and sorted_similarities[0][1] > 0.5 else None\n",
    "    return most_similar_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b831c-227f-498c-b492-9dee05458b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(processed_sentences):\n",
    "    target_list = processed_sentences\n",
    "\n",
    "    data = {'Tank 1': processed_sentences}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Process the DataFrame\n",
    "    df['Replaced Phrases'] = df['Tank 1'].apply(process_list)\n",
    "\n",
    "    for row in df['Replaced Phrases']:\n",
    "        for item in row:\n",
    "            if item is None:\n",
    "                row.remove(item)\n",
    "\n",
    "    row_list = []\n",
    "    index_number = 0\n",
    "\n",
    "    for row in df['Replaced Phrases']:\n",
    "        row_values = 0\n",
    "        dict_number = 0\n",
    "        if row is not None:\n",
    "            for item in row:\n",
    "                #print(item)\n",
    "                carbon_value = food_info[item][0] # the carbon value of the food item\n",
    "                quantity = float(quantity_dict[index_number][dict_number]) # the quantity of the food item\n",
    "\n",
    "                row_values += carbon_value * quantity # the total carbon value of that item\n",
    "                dict_number += 1\n",
    "            \n",
    "        index_number += 1\n",
    "        row_list.append(row_values)\n",
    "\n",
    "    df['Carbon Value (g)'] = row_list\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89826636-055c-4ab9-b52c-93157fab1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2d88a-4cc3-4d2d-8b70-25c15cb4fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# post request\n",
    "\n",
    "@app.route('/')\n",
    "def entire_process():\n",
    "    carbon_index, df2, df3, tank1 = get_data()\n",
    "    food_dict, food_info, tank1, quantity_dict, processed_sentences = data_processing(tank1)\n",
    "    word_list_vectors = model_training(model)\n",
    "\n",
    "    df = word_similarity(processed_sentences)\n",
    "    carbon_value = df['Carbon Value (g)'].sum()\n",
    "    carbon_value = str(carbon_value)\n",
    "\n",
    "    return carbon_value\n",
    "\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "tensorflowgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
